\section{未来工作}

本文将针对以下部分进一步完善AdaptiveLLM框架。

\subsubsection{张量压缩技术}

有限的PCIe传输带宽使数据的GPU-CPU传输带来无法忽略的通信开销。随着LLM参数量和批处理大小的增加，通信开销成为主要性能瓶颈。近期工作中~\cite{Swapping}，张量压缩技术常与张量交换技术联合使用，通过矩阵变换等数学方式减少传输参数量。高效的压缩技术能够在不损失张量精度的前提下减小通信开销，进一步提升批处理大小上限，提升吞吐率。

\subsubsection{内存优化与前向传播的并行}

\begin{itemize}

  \item \textbf{张量交换与前向传播的并行}：张量交换的本质是GPU-CPU通信传输过程，而前向传播的本质是GPU计算过程。二者在传统模式下串行执行。AdaptiveLLM计划在内存优化决策器中设计一个交换线程和一个计算线程，并行完成两项任务，进一步减少张量交换带来的额外开销。

  \item \textbf{张量重算与前向传播的并行}：SARATHI~\cite{SARATHI}框架研发了chunk-prefill技术，实现prefill阶段与decode阶段共置运行。由于张量重算的本质是prefill过程，因此若将该技术移植到AdaptiveLLM中，可以实现张量重算与前向传播的并行。

\end{itemize}

\subsubsection{张量并行与流水线并行~\cite{Parallelism}} AdaptiveLLM目前仅针对张量并行度与流水线并行度均为1的场景进行优化，本文将在未来实现张量并行技术与流水线并行技术。